<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Data Services</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
        }
        .container {
            max-width: 1000px; /* Increased max-width */
            margin: 0 auto;
        }
        h1 {
            text-align: center;
        }
        .question {
            margin: 20px 0;
        }
        .question label {
            display: block;
            margin-bottom: 5px;
        }
        input[type="text"],
        input[type="email"] {
            width: 100%; /* Make input fields take up the full width */
            padding: 8px;
            box-sizing: border-box;
        }
        .checklist {
            list-style: none;
            padding: 0;
        }
        .checklist li {
            margin: 5px 0;
        }
        .submit-btn {
            display: block;
            width: 100%;
            padding: 10px;
            background-color: #4CAF50;
            color: white;
            border: none;
            cursor: pointer;
            text-align: center;
        }
    </style>
</head>
<body>       
<div class="container">       
<h1>Miyagi-Do School of Data Analysis</h1>
    Our goal is to leverage data to produce meaningful insights into how the brain works.
    This does not mean applying sophisticated analysis to big data, at least as the first step.
    We are not a machine-learning company training foundation models on big neuroscience data.

    While it can be tempting to immediately apply the latest state-of-the-art dimensionality reduction method to a state-of-the-art big dataset, this approach makes it far too easy to over- or misinterpret results and produce non-reproducible findings, while often simultaneously demanding intensive computational resources.

    Our approach is always to start simple first, only leveraging more advanced methods when they are expected to produce clear, interesting results.

    We believe the first step is to "sand the floor", i.e. to simply look at the data (being mindful of the risk of p-hacking), run sanity checks on the measurement process, identify artifacts, and ensure the data has clear, interesting signal in it.

    The next step is to "paint the house" compute all the basics of the dataset, and run sanity checks against basic predictions from the literature.

    Skipping the above steps drastically increases the chance of misinterpreting the results of a more sophisticated approach.

    Only once the floor has been sanded and the fence painted do we move onto more advanced analyses.

    For advanced analyses we take the middle way, balancing between data-driven exploratory analyses and targeted hypothesis tests and model comparisons.

    A key dimension of our school of thought is to always guide analyses with predictions based on literature (and/or common sense).
    We do not believe the value of predictions is to be correct, but rather to imbue analysis results with meaning.
    If a prediction is help up by the data, this produces (some) evidence of an accurate understanding of the system.
    If a prediction is violated by the data, having made the prediction in the first place ensures the violation is interesting and provides an opportunity for greater understanding of the dataset and the system that produced it.

    We also believe that effective data analysis is a skill that can be learned by anyone, but it does take time and practice.

</div>
</body>
</html>
